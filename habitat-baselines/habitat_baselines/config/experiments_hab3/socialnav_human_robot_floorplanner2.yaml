# @package _global_

defaults:
  - _self_
habitat:
  seed: 100
  env_task: GymHabitatEnv
  env_task_gym_dependencies: []
  env_task_gym_id: ''
  environment:
    max_episode_steps: 700
    max_episode_seconds: 10000000
    iterator_options:
      cycle: true
      shuffle: true
      group_by_scene: true
      num_episode_sample: -1
      max_scene_repeat_episodes: -1
      max_scene_repeat_steps: 10000
      step_repetition_range: 0.2
  simulator:
    type: RearrangeSim-v0
    action_space_config: v0
    action_space_config_arguments: {}
    forward_step_size: 0.25
    create_renderer: false
    requires_textures: true
    auto_sleep: true
    step_physics: false
    concur_render: true
    needs_markers: true
    update_articulated_agent: true
    scene: data/scene_datasets/habitat-test-scenes/van-gogh-room.glb
    scene_dataset: default
    additional_object_paths:
    - data/objects/ycb/configs/
    - data/objects/amazon_berkeley/configs/
    - data/objects/google_object_dataset/configs/
    seed: 100
    turn_angle: 10
    tilt_angle: 15
    default_agent_id: 0
    debug_render: false
    debug_render_articulated_agent: false
    kinematic_mode: true
    debug_render_goal: true
    robot_joint_start_noise: 0.0
    ctrl_freq: 120.0
    ac_freq_ratio: 1
    load_objs: true
    hold_thresh: 0.15
    grasp_impulse: 10000.0
    agents:
      agent_0:
        height: 1.8
        radius: 0.25
        max_climb: 0.01
        grasp_managers: 1
        sim_sensors:
          head_rgb_sensor:
            type: HabitatSimRGBSensor
            height: 256
            width: 256
            position:
            - 0.0
            - 1.25
            - 0.0
            orientation:
            - 0.0
            - 0.0
            - 0.0
            hfov: 90
            sensor_subtype: PINHOLE
            noise_model: None
            noise_model_kwargs: {}
            uuid: head_rgb
          head_depth_sensor:
            type: HabitatSimDepthSensor
            height: 256
            width: 256
            position:
            - 0.0
            - 1.25
            - 0.0
            orientation:
            - 0.0
            - 0.0
            - 0.0
            hfov: 90
            sensor_subtype: PINHOLE
            noise_model: None
            noise_model_kwargs: {}
            min_depth: 0.0
            max_depth: 10.0
            normalize_depth: true
            uuid: head_depth
          arm_rgb_sensor:
            type: HabitatSimRGBSensor
            height: 480
            width: 640
            position:
            - 0.0
            - 1.25
            - 0.0
            orientation:
            - 0.0
            - 0.0
            - 0.0
            hfov: 47
            sensor_subtype: PINHOLE
            noise_model: None
            noise_model_kwargs: {}
            uuid: articulated_agent_arm_rgb
          arm_depth_sensor:
            type: HabitatSimDepthSensor
            height: 224
            width: 171
            position:
            - 0.0
            - 1.25
            - 0.0
            orientation:
            - 0.0
            - 0.0
            - 0.0
            hfov: 55
            sensor_subtype: PINHOLE
            noise_model: None
            noise_model_kwargs: {}
            min_depth: 0.0
            max_depth: 10.0
            normalize_depth: true
            uuid: articulated_agent_arm_depth
        is_set_start_state: false
        start_position:
        - 0.0
        - 0.0
        - 0.0
        start_rotation:
        - 0.0
        - 0.0
        - 0.0
        - 1.0
        joint_start_noise: 0.0
        articulated_agent_urdf: data/robots/hab_spot_arm/urdf/hab_spot_arm.urdf
        articulated_agent_type: SpotRobot
        ik_arm_urdf: ./data/robots/hab_fetch/robots/fetch_onlyarm.urdf
        motion_data_path: ''
        rest_pose_data_path: ''
      agent_1:
        height: 1.5
        radius: 0.3
        max_climb: 0.01
        grasp_managers: 1
        sim_sensors:
          head_depth_sensor:
            type: HabitatSimDepthSensor
            height: 256
            width: 256
            position:
            - 0.0
            - 1.25
            - 0.0
            orientation:
            - 0.0
            - 0.0
            - 0.0
            hfov: 90
            sensor_subtype: PINHOLE
            noise_model: None
            noise_model_kwargs: {}
            min_depth: 0.0
            max_depth: 10.0
            normalize_depth: true
            uuid: head_depth
        is_set_start_state: false
        start_position:
        - 0.0
        - 0.0
        - 0.0
        start_rotation:
        - 0.0
        - 0.0
        - 0.0
        - 1.0
        joint_start_noise: 0.1
        articulated_agent_urdf: data/humanoids/humanoid_data/female2_0.urdf
        articulated_agent_type: KinematicHumanoid
        ik_arm_urdf: data/robots/hab_fetch/robots/fetch_onlyarm.urdf
        motion_data_path: data/humanoids/humanoid_data/walking_motion_processed_smplx.pkl
        rest_pose_data_path: data/humanoids/humanoid_data/standing_pose_smplx.pkl
    agents_order:
    - agent_0
    - agent_1
    habitat_sim_v0:
      gpu_device_id: 0
      gpu_gpu: false
      allow_sliding: true
      frustum_culling: true
      enable_physics: true
      physics_config_file: ./data/default.physics_config.json
      leave_context_with_background_renderer: false
      enable_gfx_replay_save: false
    ep_info: null
    object_ids_start: 100
    renderer:
      enable_batch_renderer: false
      composite_files: null
      classic_replay_renderer: false
  task:
    reward_measure: social_nav_reward
    success_measure: composite_success
    success_reward: 0.0
    slack_reward: 0.0
    end_on_success: true
    type: RearrangeCompositeTask-v0
    lab_sensors:
      relative_resting_pos_sensor:
        type: RelativeRestingPositionSensor
      target_start_sensor:
        type: TargetStartSensor
        goal_format: CARTESIAN
        dimensionality: 3
      goal_sensor:
        type: GoalSensor
        goal_format: CARTESIAN
        dimensionality: 3
      joint_sensor:
        type: JointSensor
        dimensionality: 7
      is_holding_sensor:
        type: IsHoldingSensor
      end_effector_sensor:
        type: EEPositionSensor
      target_start_gps_compass_sensor:
        type: TargetStartGpsCompassSensor
      target_goal_gps_compass_sensor:
        type: TargetGoalGpsCompassSensor
      localization_sensor:
        type: LocalizationSensor
      has_finished_oracle_nav:
        type: HasFinishedOracleNavSensor
      other_agent_gps:
        type: OtherAgentGps
    measurements:
      composite_success:
        type: CompositeSuccess
        must_call_stop: false
      num_steps:
        type: NumStepsMeasure
      did_agents_collide:
        type: DidAgentsCollide
      composite_stage_goals:
        type: CompositeStageGoals
      cooperate_subgoal_reward:
        type: CooperateSubgoalReward
        stage_sparse_reward: 5.0
        end_on_collide: true
        collide_penalty: 0.5
      social_nav_reward:
        type: SocialNavReward
      composite_subgoal_reward:
        type: CompositeSubgoalReward
        stage_sparse_reward: 1.0
      runtime_perf_stats:
        type: RuntimePerfStats
      finding_success_rate:
        type: FindingSuccessRate
      following_rate:
        type: FollowingRate
      following_distance:
        type: FollowingDistance
    goal_sensor_uuid: pointgoal
    count_obj_collisions: true
    settle_steps: 5
    constraint_violation_ends_episode: false
    constraint_violation_drops_object: true
    force_regenerate: false
    should_save_to_cache: false
    object_in_hand_sample_prob: 0.167
    min_start_distance: 3.0
    render_target: true
    physics_stability_steps: 1
    num_spawn_attempts: 200
    spawn_max_dist_to_obj: 2.0
    base_angle_noise: 0.523599
    recep_place_shrink_factor: 0.8
    ee_sample_factor: 0.2
    ee_exclude_region: 0.0
    base_noise: 0.05
    spawn_region_scale: 0.2
    joint_max_impulse: -1.0
    desired_resting_position:
    - 0.5
    - 0.0
    - 1.0
    use_marker_t: true
    cache_robot_init: false
    success_state: 0.0
    should_enforce_target_within_reach: false
    task_spec_base_path: habitat/task/rearrange/pddl/
    task_spec: multi_agent_tidy_house_fp
    pddl_domain_def: fp
    obj_succ_thresh: 0.3
    enable_safe_drop: false
    art_succ_thresh: 0.15
    robot_at_thresh: 3.0
    actions:
      agent_0_base_velocity:
        type: BaseVelAction
        agent_index: 0
        lin_speed: 40.0
        ang_speed: 20.0
        allow_dyn_slide: true
        allow_back: true
      agent_1_base_velocity:
        type: BaseVelAction
        agent_index: 1
        lin_speed: 40.0
        ang_speed: 20.0
        allow_dyn_slide: true
        allow_back: true
      agent_1_rearrange_stop:
        type: RearrangeStopAction
        agent_index: 1
      agent_1_pddl_apply_action:
        type: PddlApplyAction
        agent_index: 1
      agent_1_oracle_nav_soc_action:
        type: OracleNavSocAction
        agent_index: 1
        motion_control: human_joints
        num_joints: 17
        turn_velocity: 1.0
        forward_velocity: 1.0
        turn_thresh: 0.1
        dist_thresh: 0.2
        lin_speed: 10.0
        ang_speed: 10.0
        allow_dyn_slide: true
        allow_back: true
        spawn_max_dist_to_obj: 2.0
        num_spawn_attempts: 200
      agent_0_arm_action:
        type: ArmAction
        agent_index: 0
        arm_controller: ArmRelPosAction
        grip_controller: MagicGraspAction
        arm_joint_mask: null
        arm_joint_dimensionality: 7
        grasp_thresh_dist: 0.15
        disable_grip: false
        delta_pos_limit: 0.0125
        ee_ctrl_lim: 0.015
        should_clip: false
        render_ee_target: false
        gaze_distance_range: null
        center_cone_angle_threshold: 0.0
        center_cone_vector: null
  dataset:
    type: RearrangeDataset-v0
    split: train
    scenes_dir: data/replica_cad/
    content_scenes:
    - '*'
    data_path: data/datasets/floorplanner/rearrange/scratch/train/microtrain_small_size_v0.3.1.json.gz
  gym:
    obs_keys:
    - agent_0_articulated_agent_arm_depth
    - agent_0_relative_resting_position
    - agent_0_obj_start_sensor
    - agent_0_obj_goal_sensor
    - agent_0_obj_start_gps_compass
    - agent_0_obj_goal_gps_compass
    - agent_0_is_holding
    - agent_0_ee_pos
    - agent_0_localization_sensor
    - agent_0_other_agent_gps
    - agent_1_head_depth
    - agent_1_relative_resting_position
    - agent_1_obj_start_sensor
    - agent_1_obj_goal_sensor
    - agent_1_obj_start_gps_compass
    - agent_1_obj_goal_gps_compass
    - agent_1_is_holding
    - agent_1_ee_pos
    - agent_1_localization_sensor
    - agent_1_has_finished_oracle_nav
    - agent_1_other_agent_gps
    - agent_1_has_finished_oracle_nav
    action_keys: null
    achieved_goal_keys: []
    desired_goal_keys: []
habitat_baselines:
  evaluate: false
  trainer_name: ddppo
  updater_name: HRLPPO
  distrib_updater_name: HRLDDPPO
  torch_gpu_id: 1
  tensorboard_dir: ${hydra:sweep.dir}/${hydra:sweep.subdir}/tb
  writer_type: wb
  video_dir: ${hydra:sweep.dir}/${hydra:sweep.subdir}/video
  video_fps: 30
  test_episode_count: -1
  eval_ckpt_path_dir: ${hydra:sweep.dir}/${hydra:sweep.subdir}/checkpoints
  num_environments: 1
  num_processes: -1
  rollout_storage_name: HrlRolloutStorage
  checkpoint_folder: ${hydra:sweep.dir}/${hydra:sweep.subdir}/checkpoints
  num_updates: -1
  num_checkpoints: 10
  checkpoint_interval: -1
  total_num_steps: 100000000.0
  log_interval: 1
  log_file: ${hydra:sweep.dir}/${hydra:sweep.subdir}/train.log
  force_blind_policy: false
  verbose: false
  eval_keys_to_include_in_name:
  - composite_success
  force_torch_single_threaded: true
  wb:
    project_name: social_navigation
    entity: tgervet
    group: ''
    run_name: ${hydra:job.name}_${now:%Y-%m-%d}_${now:%H-%M-%S}
  load_resume_state_config: false
  eval:
    split: val
    should_load_ckpt: false
    evals_per_ep: 1
    video_option:
    - disk
    extra_sim_sensors:
      third_rgb_sensor:
        type: HabitatSimRGBSensor
        height: 256
        width: 256
        position:
        - 0.0
        - 1.25
        - 0.0
        orientation:
        - 0.0
        - 0.0
        - 0.0
        hfov: 90
        sensor_subtype: PINHOLE
        noise_model: None
        noise_model_kwargs: {}
        uuid: third_rgb
  profiling:
    enable_perf_logger: false
    perf_logger_skip_interval: 10
    capture_start_step: -1
    num_steps_to_capture: -1
  rl:
    agent:
      type: MultiAgentAccessMgr
      num_agent_types: 2
      num_active_agents_per_type:
      - 1
      - 1
      num_pool_agents_per_type:
      - 1
      - 8
      agent_sample_interval: 20
      force_partner_sample_idx: -1
      behavior_latent_dim: -1
      force_all_agents: false
      discrim_reward_weight: 1.0
      allow_self_play: false
      self_play_batched: false
    preemption:
      append_slurm_job_id: false
      save_resume_state_interval: 100
      save_state_batch_only: false
    policy:
      agent_0:
        name: PointNavResNetPolicy
        action_distribution_type: gaussian
        action_dist:
          use_log_std: true
          use_softplus: false
          std_init: ???
          log_std_init: 0.0
          use_std_param: false
          clamp_std: true
          min_std: 1.0e-06
          max_std: 1
          min_log_std: -5
          max_log_std: 2
          action_activation: tanh
          scheduled_std: false
        obs_transforms:
          add_virtual_keys:
            type: AddVirtualKeys
            virtual_keys: {}
      agent_1:
        name: HierarchicalPolicy
        action_distribution_type: categorical
        action_dist:
          use_log_std: true
          use_softplus: false
          std_init: ???
          log_std_init: 0.0
          use_std_param: false
          clamp_std: true
          min_std: 1.0e-06
          max_std: 1
          min_log_std: -5
          max_log_std: 2
          action_activation: tanh
          scheduled_std: false
        obs_transforms:
          add_virtual_keys:
            type: AddVirtualKeys
            virtual_keys:
              goal_to_agent_gps_compass: 2
        hierarchical_policy:
          high_level_policy:
            name: SocNavHumanHighLevelPolicy
            add_arm_rest: false
            policy_input_keys:
            - head_depth
            - is_holding
            - obj_start_gps_compass
            - obj_goal_gps_compass
            - other_agent_gps
          defined_skills:
            open_cab:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: true
              ignore_grip: true
              obs_skill_inputs: []
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names:
              - open_cab_by_name
            open_fridge:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: true
              ignore_grip: true
              obs_skill_inputs: []
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names:
              - open_fridge_by_name
            close_cab:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: false
              ignore_grip: true
              obs_skill_inputs:
              - obj_start_sensor
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names:
              - close_cab_by_name
            close_fridge:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: true
              ignore_grip: true
              obs_skill_inputs:
              - obj_start_sensor
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names:
              - close_fridge_by_name
            pick:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: true
              ignore_grip: true
              obs_skill_inputs:
              - obj_start_sensor
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names: null
            place:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: true
              ignore_grip: true
              obs_skill_inputs:
              - obj_goal_sensor
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names: null
            wait:
              skill_name: WaitSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: -1
              force_end_on_timeout: true
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: false
              ignore_grip: true
              obs_skill_inputs: []
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names: null
            nav_to_obj:
              skill_name: OracleNavSocPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1500
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: false
              ignore_grip: true
              obs_skill_inputs:
              - obj_start_sensor
              - abs_obj_start_sensor
              - obj_goal_sensor
              - abs_obj_goal_sensor
              obs_skill_input_dim: 2
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names:
              - nav_to_obj
              - nav_to_goal
              - nav_to_receptacle_by_name
            reset_arm:
              skill_name: NoopSkillPolicy
              name: PointNavResNetPolicy
              action_distribution_type: gaussian
              load_ckpt_file: ''
              max_skill_steps: 1
              force_end_on_timeout: false
              force_config_file: ''
              at_resting_threshold: 0.15
              apply_postconds: false
              ignore_grip: true
              obs_skill_inputs: []
              obs_skill_input_dim: 3
              start_zone_radius: 0.3
              action_name: base_velocity
              stop_thresh: 0.001
              reset_joint_state: ???
              pddl_action_names: null
          use_skills: {}
    ppo:
      clip_param: 0.2
      ppo_epoch: 1
      num_mini_batch: 2
      value_loss_coef: 0.5
      entropy_coef: 0.0001
      lr: 0.00025
      eps: 1.0e-05
      max_grad_norm: 0.2
      num_steps: 128
      use_gae: true
      use_linear_lr_decay: false
      use_linear_clip_decay: false
      gamma: 0.99
      tau: 0.95
      reward_window_size: 50
      use_normalized_advantage: false
      hidden_size: 512
      entropy_target_factor: 0.0
      use_adaptive_entropy_pen: false
      use_clipped_value_loss: true
      use_double_buffered_sampler: false
    ddppo:
      sync_frac: 0.6
      distrib_backend: NCCL
      rnn_type: LSTM
      num_recurrent_layers: 2
      backbone: resnet18
      pretrained_weights: data/ddppo-models/gibson-2plus-resnet50.pth
      pretrained: false
      pretrained_encoder: false
      train_encoder: true
      reset_critic: false
      force_distributed: false
    ver:
      variable_experience: true
      num_inference_workers: 2
      overlap_rollouts_and_learn: false
    auxiliary_losses: {}
